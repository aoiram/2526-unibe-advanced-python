{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5498aa82",
   "metadata": {},
   "source": [
    "# Working with structured data - Part 1\n",
    "\n",
    "This notebook accompanies the script <strong><span style=\"color:red;\">06_pandas_part_B.pdf</span></strong>  and provides practical examples related to its content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f6aab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f398a0c6",
   "metadata": {},
   "source": [
    "<hr style=\"border: none; height: 20px; background-color: green;\">\n",
    "\n",
    "# 1. Hierarchical Indexing with MultiIndex\n",
    "\n",
    "### Reminder: Indexing a **Series**\n",
    "A `Series` maps **index labels** to values. Here we track the population of US states in 2000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cb1dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "populations = [33871648, 18976457, 20851820]\n",
    "index = ['California', 'New York', 'Texas']\n",
    "state_population_2000 = pd.Series(populations, index=index)\n",
    "state_population_2000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a80445",
   "metadata": {},
   "source": [
    "### Hierarchical Indexing - The \"bad/tempting\" way: tuples as keys\n",
    "If we track both `state` and `year`, it is tempting to use tuples as the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a68cdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [\n",
    "    ('California', 2000), ('California', 2010),\n",
    "    ('New York', 2000), ('New York', 2010),\n",
    "    ('Texas', 2000), ('Texas', 2010),\n",
    "]\n",
    "populations = [33871648, 37253956, \n",
    "               18976457, 19378102, \n",
    "               20851820, 25145561]\n",
    "ser_state_population = pd.Series(populations, index=index)\n",
    "ser_state_population"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330debb3",
   "metadata": {},
   "source": [
    "Direct indexing with tuple keys works, and slicing can work if the index is sorted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef45ab23",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_state_population[('California', 2010)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13ad999",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_state_population[('California', 2010):('Texas', 2010)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0460a89",
   "metadata": {},
   "source": [
    "#### Accessing All States for a Specific Year (2010)\n",
    "\n",
    "This is a bit trickier because tuples are used as the index, so we need to filter the data (with Fancy indexing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838043e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_state_population.loc[[idx for idx in ser_state_population.index if idx[1] == 2010]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686c6193",
   "metadata": {},
   "source": [
    "### A cleaner way: A real `MultiIndex`\n",
    "Use `pd.MultiIndex.from_tuples()` so `state` and `year` become separate index levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b421ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [\n",
    "    ('California', 2000), ('California', 2010),\n",
    "    ('New York', 2000), ('New York', 2010),\n",
    "    ('Texas', 2000), ('Texas', 2010),\n",
    "]\n",
    "index = pd.MultiIndex.from_tuples(index)\n",
    "index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d11268",
   "metadata": {},
   "source": [
    "#### Setting `index.names` helps us label the hierarchy in our `MultiIndex`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b66c58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.names = ['state', 'year']\n",
    "index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da91ca7",
   "metadata": {},
   "source": [
    "#### Create the multi-indexed Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5547ebd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "populations = [33871648, 37253956, \n",
    "               18976457, 19378102, \n",
    "               20851820, 25145561]\n",
    "ser_state_population = pd.Series(populations, index=index)\n",
    "ser_state_population"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c28184",
   "metadata": {},
   "source": [
    "### Multi-indexed Series: Attributes\n",
    "\n",
    "#### Levels\n",
    "Shows the unique values at each level of the MultiIndex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916e89f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = ser_state_population.index\n",
    "print('Levels:', idx.levels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b949c99c",
   "metadata": {},
   "source": [
    "#### Codes\n",
    "Encodes which level values correspond to each row in the MultiIndex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff68ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Codes:', idx.codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e08bb2",
   "metadata": {},
   "source": [
    "#### Names (index.names)\n",
    "Labels each level of the MultiIndex for better readability and operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe564952",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Names:', idx.names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81dc208",
   "metadata": {},
   "source": [
    "### Selecting with `.xs()`\n",
    "`.xs()` selects data across a specific index level in a MultiIndex Series or DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa35a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_state_population.xs(2010, level='year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa39c31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_state_population.xs('California', level='state')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b3db45",
   "metadata": {},
   "source": [
    "### Comparing `.loc[]`, `.xs()`, and `.iloc[]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c701fb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .loc[] (label-based)\n",
    "print('California 2010:', ser_state_population.loc[('California', 2010)])\n",
    "print('\\nAll years for California:\\n', ser_state_population.loc['California'])\n",
    "print('\\nAll states for 2010:\\n', ser_state_population.loc[:, 2010])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d426de97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .xs() (level-based)\n",
    "print('\\nAll states for 2010 with .xs():\\n', ser_state_population.xs(2010, level='year'))\n",
    "print('\\nGet population for all years for California:\\n', ser_state_population.xs('California', level='state'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba436386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .iloc[] (position-based)\n",
    "print('\\nRow index 2:', ser_state_population.iloc[2])\n",
    "print('Last row:', ser_state_population.iloc[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558a1ef1",
   "metadata": {},
   "source": [
    "## Reshaping with `.unstack()` and `.stack()`\n",
    "`.unstack()` turns one index level into columns, adding a new dimension.    \n",
    "`.stack()` reverses that operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86eb51ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_state_population = ser_state_population.unstack()\n",
    "print(type(ser_state_population))\n",
    "df_state_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45840845",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_state_population = df_state_population.stack()\n",
    "print(type(ser_state_population))\n",
    "ser_state_population"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561b01e8",
   "metadata": {},
   "source": [
    "## MultiIndex from an existing DataFrame\n",
    "\n",
    "Often you start with a regular DataFrame and then call `.set_index()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa0ca50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_state_population = pd.read_csv('../data/csv/population_dataset.csv')\n",
    "df_state_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f52d385",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_population_df = df_state_population.set_index(['State', 'Year'])\n",
    "state_population_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febbef99",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_population_df.unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364b4c8d",
   "metadata": {},
   "source": [
    "### Simulating a 5D Dataset with MultiIndex in Pandas\n",
    "A MultiIndex can represent higher-dimensional data in a structured way inside a 2D table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da1700b",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = ['USA', 'Germany']\n",
    "years = [2000, 2010]\n",
    "genders = ['Male', 'Female']\n",
    "age_groups = ['0-18', '19-65', '65+']\n",
    "income_groups = ['Low', 'Medium', 'High']\n",
    "\n",
    "multi_index = pd.MultiIndex.from_product(\n",
    "    [countries, years, genders, age_groups, income_groups],\n",
    "    names=['Country', 'Year', 'Gender', 'Age Group', 'Income Group']\n",
    ")\n",
    "\n",
    "values = np.random.randint(1_000, 100_000, size=len(multi_index))\n",
    "\n",
    "df_5d = pd.DataFrame({'Population': values}, index=multi_index)\n",
    "df_5d.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cd4f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Population of females aged 19–65 in Germany in 2000\n",
    "df_5d.xs(('Germany', 2000, 'Female', '19-65'), level=['Country', 'Year', 'Gender', 'Age Group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5057e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare male vs. female population for a specific year\n",
    "df_5d.xs(2010, level='Year').groupby('Gender').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab08db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unstack to turn Income Group and Age Group into columns\n",
    "df_5d.unstack(['Income Group', 'Age Group'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8f0677",
   "metadata": {},
   "source": [
    "### Why Use Hierarchical Indexing?\n",
    "\n",
    "MultiIndex allows us to efficiently organize structured data while keeping it in a single DataFrame and access it easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7487c5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create MultiIndex using from_product()\n",
    "states = ['California', 'New York', 'Texas']\n",
    "years = [2000, 2010]\n",
    "index = pd.MultiIndex.from_product([states, years], names=['State', 'Year'])\n",
    "\n",
    "# Define economic data\n",
    "gdp = [1500, 2000, 900, 1100, 1200, 1600]  # in billion USD\n",
    "unemployment_rate = [5.2, 6.1, 4.5, 5.3, 6.2, 7.0]  # In %\n",
    "\n",
    "# Create DataFrame with MultiIndex\n",
    "state_economy = pd.DataFrame(\n",
    "    {\n",
    "        'GDP (in billion USD)': gdp,\n",
    "        'Unemployment Rate (%)': unemployment_rate\n",
    "    },\n",
    "    index=index\n",
    ")\n",
    "\n",
    "state_economy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d8c688",
   "metadata": {},
   "source": [
    "### Applying NumPy ufuncs to MultiIndex DataFrames\n",
    "\n",
    "All universal functions and other Pandas operations work seamlessly with hierarchical indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e39d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute mean and standard deviation of the unemployment rate\n",
    "mean_unemployment = state_economy[\"Unemployment Rate (%)\"].mean()\n",
    "std_unemployment = state_economy[\"Unemployment Rate (%)\"].std()\n",
    "\n",
    "# Apply NumPy ufunc to standardize (Z-Score Normalization)\n",
    "state_economy[\"Unemployment Rate (Z-Score)\"] = (\n",
    "    (state_economy[\"Unemployment Rate (%)\"] - mean_unemployment) / std_unemployment\n",
    ")\n",
    "\n",
    "state_economy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd7629c",
   "metadata": {},
   "source": [
    "### Creating a `MultiIndex` by Passing Multiple Index Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25351a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    np.random.rand(4, 2),\n",
    "    index=[\n",
    "        ['a', 'a', 'b', 'b'],\n",
    "        [1, 2, 1, 2]\n",
    "    ],\n",
    "    columns=['data1', 'data2']\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f105c5e",
   "metadata": {},
   "source": [
    "#### Creating a `MultiIndex` from a `Dictionary` with Tuple Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2df0352",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    ('California', 2000): 33871648,\n",
    "    ('California', 2010): 37253956,\n",
    "    ('Texas', 2000): 20851820,\n",
    "    ('Texas', 2010): 25145561,\n",
    "    ('New York', 2000): 18976457,\n",
    "    ('New York', 2010): 19378102\n",
    "}\n",
    "\n",
    "series = pd.Series(data)\n",
    "\n",
    "series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee6aba5",
   "metadata": {},
   "source": [
    "### `MultiIndex` for columns\n",
    "Rows and columns are symmetric: both can have multiple index levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b94c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pd.MultiIndex.from_product(\n",
    "    [[2023, 2024], [1, 2]],\n",
    "    names=['year', 'visit']\n",
    ")\n",
    "\n",
    "columns = pd.MultiIndex.from_product(\n",
    "    [['Bob', 'Guido', 'Sue'], ['HR', 'Temp']],\n",
    "    names=['subject', 'type']\n",
    ")\n",
    "\n",
    "# Mock some data\n",
    "data = np.round(np.random.randn(4, 6), 1)\n",
    "data[:, ::2] *= 10  # Scale HR values\n",
    "data += 37          # Shift values to a reasonable range\n",
    "\n",
    "# Create the DataFrame\n",
    "health_data = pd.DataFrame(data, index=index, columns=columns)\n",
    "\n",
    "health_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8713cbc6",
   "metadata": {},
   "source": [
    "<hr style=\"border: none; height: 20px; background-color: green;\">\n",
    "\n",
    "# 2. Working with Missing Data\n",
    "\n",
    "Missing values are common in real-world datasets. Pandas supports several sentinel values:\n",
    "- `None` (Python)\n",
    "- `np.nan` (IEEE floating point NaN)\n",
    "- `pd.NA` (Pandas nullable missing value)\n",
    "- `pd.NaT` (missing timestamps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b3f17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# None forces object dtype if mixed into numeric Python lists\n",
    "arr_obj = np.array([1, 2, None, 4], dtype=object)\n",
    "arr_obj, arr_obj.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2bc835",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"A\": [1, 2, None, 4]})\n",
    "print(df[\"A\"].dtype)  # A becomes float64\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89eb995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaN lives in float arrays; inserting NaN upcasts integer data to float\n",
    "series = pd.Series([1, 2, np.nan, 4])\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23df154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# None in string column → becomes object\n",
    "df = pd.DataFrame({\"A\": [\"apple\", None, \"banana\", \"cherry\"]})\n",
    "print(df[\"A\"].dtype)  # A becomes object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279f6f7d",
   "metadata": {},
   "source": [
    "## The 1st downside of having None and data types objects\n",
    "\n",
    "Operations on object dtype are significantly slower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a24998d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare performance: int vs object dtype\n",
    "\n",
    "df_int = pd.DataFrame({\"A\": np.arange(1e6, dtype='int')})\n",
    "%timeit df_int[\"A\"].sum()\n",
    "\n",
    "df_object = pd.DataFrame({\"A\": np.arange(1e6, dtype='object')})\n",
    "%timeit df_object[\"A\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b230f97b",
   "metadata": {},
   "source": [
    "### Handling Missing Values in Integer Arrays\n",
    "\n",
    "#### 1. Use a Special Placeholder Valu (e.g. `-1`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6eeab5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integer array (cannot contain NaN)\n",
    "arr = np.array([1, 2, -1, 4], dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5b7354",
   "metadata": {},
   "source": [
    "#### 2. Convert to Float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27881a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Float array (can contain NaN)\n",
    "arr = np.array([1, 2, np.nan, 4], dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770999d2",
   "metadata": {},
   "source": [
    "#### 3. Use `numpy.ma.MaskedArray`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0bfe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask the third value using a masked array\n",
    "arr = np.ma.masked_array(arr, mask=[0, 0, 1, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb06e288",
   "metadata": {},
   "source": [
    "#### 4. Use `pd.NA` in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1098c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas nullable integer Series (supports missing values)\n",
    "series = pd.Series([1, 2, pd.NA, 4], dtype=pd.Int8Dtype())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d974e836",
   "metadata": {},
   "source": [
    "## The 2nd downside of having None and data types objects\n",
    "\n",
    "- Unlike NaN, None is not a numerical value and cannot participate in mathematical operations\n",
    "- Trying to apply aggregated functions like sum() or min() on an array containing None will raise an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b268df72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy array with None (becomes object dtype → sum fails)\n",
    "arr = np.array([1, 2, None, 4])\n",
    "\n",
    "try:\n",
    "    result = arr.sum()\n",
    "    print(\"Sum:\", result)\n",
    "\n",
    "except TypeError as e:\n",
    "    print(\"TypeError during sum:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0d78a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas DataFrame handles None as missing value\n",
    "df = pd.DataFrame({\"A\": [1, 2, None, 4]})\n",
    "df.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f172526",
   "metadata": {},
   "source": [
    "### The IEEE Way to Handle Missing Data: NaN (Not a Number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3023a3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "\n",
    "def float_to_ieee754(value):\n",
    "    \"\"\"Convert a float to its 64-bit IEEE 754 binary representation.\"\"\"\n",
    "    bits = struct.unpack('<Q', struct.pack('<d', value))[0]\n",
    "    sign = (bits >> 63) & 0x1\n",
    "    exponent = (bits >> 52) & 0x7FF\n",
    "    significand = bits & 0xFFFFFFFFFFFFF  # 52-bit significand\n",
    "\n",
    "    print(f\"Value: {value}\")\n",
    "    print(f\"Sign: {sign} | Exponent: {bin(exponent)} | Significand: {bin(significand)}\")\n",
    "    print(f\"Full 64-bit IEEE 754 representation: {bin(bits)}\\n\")\n",
    "\n",
    "\n",
    "float_to_ieee754(np.nan)\n",
    "float_to_ieee754(np.inf)\n",
    "float_to_ieee754(-np.inf)  # Negative Infinity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2159b6",
   "metadata": {},
   "source": [
    "#### Any arithmetic operation involving `NaN` results in another `NaN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a23287a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaN propagates through arithmetic\n",
    "print(1 + np.nan)   # NaN\n",
    "print(0 * np.nan)   # NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99be540c",
   "metadata": {},
   "source": [
    "#### Aggregates over `NaN` values will not raise an error, but will return `NaN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6540d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregations with NaN return NaN\n",
    "vals2 = np.array([1, np.nan, 3, 4])\n",
    "print(vals2.sum(), vals2.min(), vals2.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96157ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaN-safe aggregations\n",
    "print(\n",
    "    np.nansum(vals2),\n",
    "    np.nanmin(vals2),\n",
    "    np.nanmax(vals2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee021956",
   "metadata": {},
   "source": [
    "### `NaN` and `None` in Pandas\n",
    "Pandas automatically converts standard NumPy integer arrays to float if NaN or None is assigned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c1f751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard integer Series → None forces conversion to float (NaN)\n",
    "series = pd.Series(range(2), dtype=int)\n",
    "series[0] = None\n",
    "series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163eff69",
   "metadata": {},
   "source": [
    "#### Nullable integer Series → keeps integer dtype and uses `<NA>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8cd050",
   "metadata": {},
   "outputs": [],
   "source": [
    "series = pd.Series(range(2), dtype=pd.Int16Dtype())\n",
    "series[0] = None\n",
    "series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5218af5b",
   "metadata": {},
   "source": [
    "## Detecting Null Values\n",
    "\n",
    "Pandas provides built-in methods to identify missing values in a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4f7581",
   "metadata": {},
   "outputs": [],
   "source": [
    "series = pd.Series([1.0, np.nan, 'Hello', None])\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5836ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "series.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f899112",
   "metadata": {},
   "outputs": [],
   "source": [
    "series.notnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45474e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "series[series.notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f522278",
   "metadata": {},
   "source": [
    "### Drop missing values: `dropna()`\n",
    "`dropna()` removes entire rows or columns (not single individual cells)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889125d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    [\n",
    "        [1.0, np.nan, 2],\n",
    "        [2.0, 3.0, 5],\n",
    "        [np.nan, 4.0, 6]\n",
    "    ],\n",
    "    columns=[0, 1, 2]\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657f2298",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna()  # drop rows with at least one missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd3f116",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=1)  # drop columns that contain missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c58f60",
   "metadata": {},
   "source": [
    "#### Advanced Dropping with `dropna()`\n",
    "The `dropna()` function allows more control over which rows or columns are dropped, using:\n",
    "- `how='all'` → Drops only rows/columns where all values are `NaN`\n",
    "- `thresh=n` → Keeps rows/columns with at least n non-null values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef15e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({'A': [1.0, 2.0, np.nan], \n",
    "                    'B': [np.nan, 3.0, 4.0], \n",
    "                    'C': [2, 5, 6], \n",
    "                    'D': [np.nan, np.nan, np.nan]})\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae666339",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.dropna(axis=1, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45eeed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.dropna(axis=0, thresh=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ddc9d5",
   "metadata": {},
   "source": [
    "### Filling null values `fillna()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805da6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series([1, np.nan, 2, None, 3], index=list(\"abcde\"))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94325a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN / None with 0\n",
    "data.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab49ffc",
   "metadata": {},
   "source": [
    "#### Filling null values `ffill()`, `bfill()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136568e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cd8cba",
   "metadata": {},
   "source": [
    "#### Forward filling — `ffill()`\n",
    "Replaces missing values with the previous valid value in the same row or column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b2b434",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.ffill(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50aa4329",
   "metadata": {},
   "source": [
    "#### Backward filling — `bfill()`\n",
    "Does the opposite, it replaces missing values with the next valid value, ensuring that gaps are filled based on future observations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac8d504",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.bfill(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a36658e",
   "metadata": {},
   "source": [
    "### Handling Missing Data – More Advanced Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c78fbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"A\": [1.0, 2.0, np.nan, 4.0, 5.0],\n",
    "        \"B\": [np.nan, 10.0, 15.0, 20.0, np.nan]\n",
    "    }\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48bb391",
   "metadata": {},
   "source": [
    "#### Replace missing values with the mean, median or mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7761083c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(df.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14794cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"A\"].fillna(df[\"A\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6b590a",
   "metadata": {},
   "source": [
    "#### Fill multiple columns in one step using a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ad2cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling Multiple Columns at Once\n",
    "df.fillna({\n",
    "    \"A\": df[\"A\"].mode()[0],\n",
    "    \"B\": df[\"B\"].mean()\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c4811d",
   "metadata": {},
   "source": [
    "#### Estimate missing values using linear, quadratic, or cubic interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283d12f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear, quadratic, or cubic interpolation\n",
    "df.interpolate(method=\"linear\")  # linear, quadratic, cubic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e67018",
   "metadata": {},
   "source": [
    "#### KNNImputer\n",
    "Uses K-Nearest Neighbors (KNNImputer) to fill missing values based on similar data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35f7359",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"time\": range(10),\n",
    "        \"A\": [1.0, 2.0, np.nan, 4.0, 8.0, np.nan, 20.0, 40.0, np.nan, 100.0]\n",
    "    }\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b186e603",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=3)\n",
    "pd.DataFrame(imputer.fit_transform(df), columns=df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91d7deb",
   "metadata": {},
   "source": [
    "<hr style=\"border: none; height: 20px; background-color: green;\">\n",
    "\n",
    "# 3. Concatenating Datasets\n",
    "`pd.concat()` combines Series/DataFrames along an axis:\n",
    "- `axis=0`: stack vertically (add rows)\n",
    "- `axis=1`: stack horizontally (add columns)\n",
    "\n",
    "#### Concatenations: reminder from NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40878c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1 = np.array([[1, 2], [3, 4]])\n",
    "arr2 = np.array([[5, 6]])\n",
    "\n",
    "# Concatenate along axis 0 (rows)\n",
    "concat_rows = np.concatenate([arr1, arr2], axis=0)\n",
    "print(\"Concatenated along rows:\\n\", concat_rows)\n",
    "\n",
    "# Concatenate along axis 1 (columns)\n",
    "arr3 = np.array([[5], [6]])\n",
    "concat_cols = np.concatenate([arr1, arr3], axis=1)\n",
    "print(\"\\nConcatenated along columns:\\n\", concat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c8635d",
   "metadata": {},
   "source": [
    "#### Concatenations in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3806aa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(\n",
    "    {\"A\": [1, 2], \"B\": [3, 4], \"C\": [5, 6]},\n",
    "    index=[1, 2]\n",
    ")\n",
    "\n",
    "df2 = pd.DataFrame(\n",
    "    {\"A\": [7, 8], \"B\": [9, 10]},\n",
    "    index=[3, 4]\n",
    ")\n",
    "display(df1, df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb95dce",
   "metadata": {},
   "source": [
    "#### Basic row-wise concatenation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49bf782",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df1, df2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706e690a",
   "metadata": {},
   "source": [
    "#### Basic column-wise Concatenation (`axis=1`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ff4143",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df1, df2], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a47df3a",
   "metadata": {},
   "source": [
    "#### Difference Between `np.concatenate()` and `pd.concat()`\n",
    "\n",
    "Unlike NumPy’s `np.concatenate()`, Pandas preserves indices even if they are duplicated.   \n",
    "This behavior can lead to unintended consequences when concatenating DataFrames.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609ed23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make duplicate indices\n",
    "df2.index = df1.index\n",
    "\n",
    "pd.concat([df1, df2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f061a2ee",
   "metadata": {},
   "source": [
    "### Duplicate indices\n",
    "\n",
    "Unlike NumPy’s np.concatenate(), pandas preserves indices even if they are duplicated.  \n",
    "\n",
    "By setting verify_integrity=True, pd.concat() raises a ValueError if duplicate indices are detected in the result. This helps catch unintended index duplication early, preventing potential issues when working with index-based operations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c305edca",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    pd.concat([df1, df2], verify_integrity=True)\n",
    "except ValueError as e:\n",
    "    print('ValueError:', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe1d51e",
   "metadata": {},
   "source": [
    "Reset indices during concatenation with `ignore_index=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8f1a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df1, df2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b728a8b",
   "metadata": {},
   "source": [
    "Add a key level to create a MultiIndex in the result with `keys=`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbfd667",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df1, df2], keys=['x', 'y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ff8052",
   "metadata": {},
   "source": [
    "Keep only the intersection of columns with `join='inner'` (avoids extra NaN columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23962329",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df1, df2], join='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9526942c",
   "metadata": {},
   "source": [
    "## Merging and Joining Datasets\n",
    "`pd.merge()` / `df.merge()` combine tables by aligning rows on key columns (SQL-style joins)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e0ba03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.DataFrame({\n",
    "    'employee': ['Bob', 'Jake', 'Lisa', 'Sue'],\n",
    "    'group': ['Accounting', 'Engineering', 'Engineering', 'HR']\n",
    "})\n",
    "df_2 = pd.DataFrame({\n",
    "    'employee': ['Lisa', 'Bob', 'Jake', 'Sue'],\n",
    "    'hire_date': [2004, 2008, 2012, 2014]\n",
    "})\n",
    "display(df_1, df_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1549a627",
   "metadata": {},
   "source": [
    "#### `pd.merge()` vs. `df.merge()` – Two Ways to Merge DataFrames\n",
    "Both `pd.merge()` and `df.merge()` perform the same operation, merging two DataFrames based on a key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bc3698",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df_1, df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cd3b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.merge(df_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316b9ed3",
   "metadata": {},
   "source": [
    "### The `on` Option in `pd.merge()`\n",
    "\n",
    "- The `on` parameter specifies the column(s) that should be used as the key(s) for merging\n",
    "- It ensures that the merge operation is performed based on a common identifier between both DataFrames\n",
    "- Without `on`, pandas tries to auto-detect common columns, but it's best to explicitly define them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bdea20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.merge(df_2, on='employee')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628f045c",
   "metadata": {},
   "source": [
    "### Many-to-many join\n",
    "If both sides have duplicate keys, the result can expand (cartesian product per key)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3493722",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = pd.DataFrame({\n",
    "    \"employee\": [\"Bob\", \"Jake\", \"Lisa\", \"Sue\"],\n",
    "    \"group\": [\"Accounting\", \"Engineering\", \"Engineering\", \"HR\"],\n",
    "    \"hire_date\": [2008, 2012, 2004, 2014]\n",
    "})\n",
    "\n",
    "df_4 = pd.DataFrame({\n",
    "    \"group\": [\"Accounting\", \"Engineering\", \"HR\"],\n",
    "    \"supervisor\": [\"Carly\", \"Guido\", \"Steve\"]\n",
    "})\n",
    "\n",
    "display(df_3, df_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b85bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df_3, df_4, on='group')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5ca646",
   "metadata": {},
   "source": [
    "#### Many-to-Many Joins in pd.merge()\n",
    "A Many-to-Many join occurs when both key columns in the merging DataFrames contain duplicate values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5eaca60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5 = pd.DataFrame({\n",
    "    \"employee\": [\"Bob\", \"Jake\", \"Lisa\", \"Sue\"],\n",
    "    \"group\": [\"Accounting\", \"Engineering\", \"Engineering\", \"HR\"]\n",
    "})\n",
    "\n",
    "df_6 = pd.DataFrame({\n",
    "    \"group\": [\n",
    "        \"Accounting\", \"Accounting\",\n",
    "        \"Engineering\", \"Engineering\",\n",
    "        \"HR\", \"HR\"\n",
    "    ],\n",
    "    \"skills\": [\n",
    "        \"math\", \"spreadsheets\",\n",
    "        \"coding\", \"linux\",\n",
    "        \"spreadsheets\", \"organization\"\n",
    "    ]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cef6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df_5, df_6, on='group')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7996a9",
   "metadata": {},
   "source": [
    "### Different key names: `left_on` / `right_on`\n",
    "Useful when the key column names differ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c54f3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_7 = pd.DataFrame({\n",
    "    \"name\": [\"Bob\", \"Jake\", \"Lisa\", \"Sue\"],\n",
    "    \"salary\": [70000, 80000, 120000, 90000]\n",
    "})\n",
    "\n",
    "pd.merge(df_1, df_7, left_on='employee', right_on='name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a124d763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop redundant columns if needed\n",
    "df = pd.merge(df_1, df_7, left_on='employee', right_on='name')\n",
    "df.drop('name', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e65a9d7",
   "metadata": {},
   "source": [
    "### Join strategies with `how=`\n",
    "- `inner`: keep only matches\n",
    "- `outer`: keep all rows from both sides\n",
    "- `left`: keep all left rows\n",
    "- `right`: keep all right rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252ca525",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_8 = pd.DataFrame({\n",
    "    \"employee\": [\"Bob\", \"Jake\", \"Lisa\"],\n",
    "    \"salary\": [70000, 80000, 120000]\n",
    "})\n",
    "display(df_1, df_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db660c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df_1, df_8, on='employee', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4b8f3f",
   "metadata": {},
   "source": [
    "### `.join()` merges on index by default\n",
    "Use `.join()` when your identifiers are already in the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b3d8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({\n",
    "    \"group\": [\"Accounting\", \"Engineering\", \"Engineering\", \"HR\"]\n",
    "}, index=[\"Bob\", \"Jake\", \"Lisa\", \"Sue\"])\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "    \"hire_date\": [2004, 2008, 2012, 2014]\n",
    "}, index=[\"Lisa\", \"Bob\", \"Jake\", \"Sue\"])\n",
    "display(df1, df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45923513",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.join(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcb1b9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8115b3cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-repo-py3.11 (3.11.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
